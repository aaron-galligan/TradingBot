{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa85ad4",
   "metadata": {},
   "source": [
    "## This is just gpt bullshit, gonna need to change it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bff59b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## High-Level Architecture\n",
    "\n",
    "### 1. **Modules / Files**\n",
    "\n",
    "| File                      | Purpose                                                               |\n",
    "| ------------------------- | --------------------------------------------------------------------- |\n",
    "| `main.py`                 | Orchestrates the full pipeline (scrape → features → predict → email). |\n",
    "| `scraper.py`              | Contains your `OpenInsiderScraper` class and data saving logic.       |\n",
    "| `features.py`             | Handles feature creation and data cleaning.                           |\n",
    "| `model.py`                | Loads and applies the trained XGBoost model.                          |\n",
    "| `notify.py`               | Sends email alerts or notifications.                                  |\n",
    "| `config.py`               | Holds paths, email credentials, and thresholds.                       |\n",
    "| `run_daily.sh` (optional) | A cron-friendly script to run `python main.py` daily.                 |\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "### **Step 1 — Scrape Data**\n",
    "\n",
    "```python\n",
    "from scraper import OpenInsiderScraper\n",
    "\n",
    "scraper = OpenInsiderScraper()\n",
    "data = scraper.scrape()  # returns a DataFrame of today's trades\n",
    "```\n",
    "\n",
    "### **Step 2 — Feature Engineering**\n",
    "\n",
    "```python\n",
    "from features import create_features\n",
    "\n",
    "features_df = create_features(data)\n",
    "```\n",
    "\n",
    "* Handle missing values, encode categorical fields, etc.\n",
    "* Make sure your feature order matches the model’s training columns.\n",
    "\n",
    "### **Step 3 — Load and Run Model**\n",
    "\n",
    "```python\n",
    "from model import load_model, predict_trades\n",
    "\n",
    "model = load_model(\"xgboost_model.joblib\")\n",
    "predictions = predict_trades(model, features_df)\n",
    "```\n",
    "\n",
    "* `predict_trades` returns a DataFrame with tickers, predictions, and confidence scores.\n",
    "\n",
    "### **Step 4 — Filter and Format Results**\n",
    "\n",
    "```python\n",
    "threshold = 0.7  # e.g., only include predictions above 70% probability\n",
    "alerts = predictions[predictions[\"prob_up\"] > threshold]\n",
    "```\n",
    "\n",
    "### **Step 5 — Send Email Notification**\n",
    "\n",
    "```python\n",
    "from notify import send_email\n",
    "\n",
    "if not alerts.empty:\n",
    "    send_email(alerts, subject=\"OpenInsider Daily Trade Alerts\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Example `main.py`\n",
    "\n",
    "```python\n",
    "from scraper import OpenInsiderScraper\n",
    "from features import create_features\n",
    "from model import load_model, predict_trades\n",
    "from notify import send_email\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    print(\"Starting OpenInsider pipeline...\")\n",
    "\n",
    "    # 1. Scrape data\n",
    "    scraper = OpenInsiderScraper()\n",
    "    data = scraper.scrape()\n",
    "\n",
    "    # 2. Feature engineering\n",
    "    features = create_features(data)\n",
    "\n",
    "    # 3. Load model and predict\n",
    "    model = load_model(\"xgboost_model.joblib\")\n",
    "    results = predict_trades(model, features)\n",
    "\n",
    "    # 4. Filter\n",
    "    alerts = results[results[\"prob_up\"] > 0.7]\n",
    "\n",
    "    # 5. Send email if any alerts\n",
    "    if not alerts.empty:\n",
    "        send_email(alerts, subject=f\"OpenInsider Alerts - {datetime.now():%Y-%m-%d}\")\n",
    "        print(\"Alerts sent.\")\n",
    "    else:\n",
    "        print(\"No high-confidence alerts today.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Email Example (`notify.py`)\n",
    "\n",
    "```python\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_email(df, subject):\n",
    "    body = df.to_string(index=False)\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = \"your_email@gmail.com\"\n",
    "    msg[\"To\"] = \"you@gmail.com\"\n",
    "\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "        server.login(\"your_email@gmail.com\", \"app_password_here\")\n",
    "        server.send_message(msg)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Automation (Linux/Mac)\n",
    "\n",
    "You can run it automatically:\n",
    "\n",
    "```bash\n",
    "crontab -e\n",
    "# Run every weekday at 6 PM Melbourne time\n",
    "0 18 * * 1-5 /path/to/venv/bin/python /path/to/main.py >> /path/to/log.txt 2>&1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The whole pipeline flow:\n",
    "\n",
    "```\n",
    "main.py\n",
    " ├── scraper.scrape()           → get data\n",
    " ├── features.create_features() → build features\n",
    " ├── model.predict_trades()     → generate predictions\n",
    " ├── filter by prob > X\n",
    " └── notify.send_email()        → send summary\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to show a **skeleton implementation** for each of those files (`features.py`, `model.py`, `notify.py`, etc.) so you can build it out quickly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c39e25",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
