{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8037d622",
   "metadata": {},
   "source": [
    "for more scope creep, using a 30 (or 60 or 90) day price plot estimate the most likley day that the stock will peak and use this as the sell date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed29407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "from pandas.tseries.offsets import BMonthEnd\n",
    "#from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "#import tensorflow as tf\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix # Loading required libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72053cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "<>:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "C:\\Users\\azzag\\AppData\\Local\\Temp\\ipykernel_2656\\1495930421.py:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "  .str.replace('[\\$,\\+\\-\\%>]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('2015_2025_data/insider_trades.csv', parse_dates=['transaction_date', 'trade_date'])\n",
    "df = df.dropna()\n",
    "\n",
    "for i in ['last_price', 'Qty', 'shares_held', 'Owned', 'Value']:\n",
    "    df[i] = (\n",
    "        df[i]\n",
    "        .astype(str)\n",
    "        .str.replace('New', '1000000000', regex=False)\n",
    "        .str.replace('[\\$,\\+\\-\\%>]', '', regex=True)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'], format=\"%d/%m/%Y %H:%M\")\n",
    "df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "\n",
    "#print(type(df['transaction_date']))\n",
    "#print(df['transaction_date'])\n",
    "#print(df['trade_date'])\n",
    "\n",
    "df['Owned_norm'] = 1 - np.exp(-df['Owned']*np.log(2)/100)\n",
    "\n",
    "df = df.sort_values(by='transaction_date')\n",
    "\n",
    "#df = df.loc[:499]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b3611",
   "metadata": {},
   "source": [
    "### Saving and loading varilabes with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d88baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLoading a variable\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.makedirs('saved_vars', exist_ok=True)  # create folder if it doesn't exist\n",
    "\n",
    "'''\n",
    "Saving a variable\n",
    "'''\n",
    "#with open('saved_vars/prices_for_all_tickers.pkl', 'wb') as f:\n",
    "#    pickle.dump(prices, f)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Loading a variable\n",
    "'''\n",
    "#with open('saved_vars/500_trades_from_mid_2024.pkl', 'rb') as f:  # 'rb' = read binary\n",
    "#    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed685b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_vars/all_ticker_2015_25.pkl', 'rb') as f:  # 'rb' = read binary\n",
    "    data = pickle.load(f)\n",
    "df_by_ticker = data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d982982",
   "metadata": {},
   "source": [
    "#### Load in prices from saved_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777c86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_vars/prices_for_all_tickers.pkl', 'rb') as f:  # 'rb' = read binary\n",
    "    prices = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = prices['SAL']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e85629",
   "metadata": {},
   "source": [
    "## Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a1a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prev_prices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prev_prices'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m         flags\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m last_3_days \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flags\n\u001b[1;32m---> 69\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mdf_by_ticker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Looks at the last valid trading date on or before the transaction date.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_spy_return\u001b[39m(effective_date, spy_history):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\frame.py:10381\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10369\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10370\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10371\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10379\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10380\u001b[0m )\n\u001b[1;32m> 10381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 69\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trade)\u001b[0m\n\u001b[0;32m     66\u001b[0m         flags\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m last_3_days \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flags\n\u001b[1;32m---> 69\u001b[0m features \u001b[38;5;241m=\u001b[39m df_by_ticker\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m trade: \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Looks at the last valid trading date on or before the transaction date.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_spy_return\u001b[39m(effective_date, spy_history):\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mcreate_features\u001b[1;34m(trade)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_features\u001b[39m(trade):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    ticker_data: DataFrame with OHLCV for one stock over 3 months\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Returns: Single row of engineered features:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m        '1mo_return', '3mo_return', '30d_volatility', 'rsi_14', 'macd',\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m        'volume_zscore', 'price_vs_sma50'.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     ticker_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrade\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprev_prices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m     features \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_date_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(trade[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrade_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtimestamp() \u001b[38;5;66;03m# seconds since epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\series.py:1130\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\series.py:1246\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1246\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\aaron\\OneDrive\\Documents\\Programming\\Python\\TradingBot\\botenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prev_prices'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_features(trade):\n",
    "    \"\"\"\n",
    "    ticker_data: DataFrame with OHLCV for one stock over 3 months\n",
    "    Returns: Single row of engineered features:\n",
    "        '1mo_return', '3mo_return', '30d_volatility', 'rsi_14', 'macd',\n",
    "        'volume_zscore', 'price_vs_sma50'.\n",
    "    \"\"\"\n",
    "    ticker_data = trade['prev_prices']\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    features['trade_date_epoch'] = pd.to_datetime(trade['trade_date']).timestamp() # seconds since epoch\n",
    "    features['eff_trans_date_epoch'] = pd.to_datetime(trade['eff_trans_date']).timestamp() \n",
    "\n",
    "    \n",
    "    # Price returns\n",
    "    features['1mo_return'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].iloc[-22] - 1\n",
    "    features['3mo_return'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].iloc[-63] - 1\n",
    "    \n",
    "    # Volatility\n",
    "    features['30d_volatility'] = ticker_data['Close'].pct_change().std() * np.sqrt(252)\n",
    "    \n",
    "    # Momentum indicators\n",
    "    # RSI 14\n",
    "    rsi = RSIIndicator(close=ticker_data['Close'], window=14).rsi()  # series\n",
    "    features['rsi_14'] = rsi.iloc[-1]\n",
    "    # MACD line\n",
    "    macd = MACD(close=ticker_data['Close'])\n",
    "    features['macd'] = macd.macd().iloc[-1]  # MACD line\n",
    "    \n",
    "    # Volume\n",
    "    features['volume_zscore'] = (\n",
    "        (ticker_data['Volume'].iloc[-1] - ticker_data['Volume'].mean()) \n",
    "        / ticker_data['Volume'].std()\n",
    "    )\n",
    "    \n",
    "    # Trend relationships\n",
    "    features['price_vs_sma50'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].rolling(50).mean().iloc[-1]\n",
    "\n",
    "    # Bool on whether the transaction was made within trading hours.\n",
    "    features['is_during_market_hours'] = time(hour=9, minute=30) < trade['transaction_date'].time() < time(hour=16)\n",
    "\n",
    "    # Day of the week the trade was made on.\n",
    "    features['day_of_week'] = trade['trade_date'].dayofweek\n",
    "\n",
    "    # Number of days between making the trade and filing with the SEC\n",
    "    features['filing_lad_days'] = (trade['transaction_date']-trade['trade_date']).days\n",
    "\n",
    "    #df_by_ticker = df_by_ticker.dropna()\n",
    "    \n",
    "    title_str = ''.join(trade['Title'])\n",
    "    if 'CEO' in title_str:\n",
    "        features['title_rank'] = 4\n",
    "    elif 'C' in title_str:\n",
    "        features['title_rank'] = 3\n",
    "    elif 'Dir' in title_str:\n",
    "        features['title_rank'] = 2\n",
    "    else:\n",
    "        features['title_rank'] = 1\n",
    "        \n",
    "    return pd.Series(features)\n",
    "\n",
    "\n",
    "def flag_month_end(trade_dates):\n",
    "    \"\"\"Returns 1 for last 3 business days of month\"\"\"\n",
    "    flags = []\n",
    "    for date in trade_dates:\n",
    "        month_end = BMonthEnd().rollforward(date)  # Get official month-end\n",
    "        last_3_days = pd.bdate_range(end=month_end, periods=3)  # Last 3 trading days\n",
    "        flags.append(1 if date in last_3_days else 0)\n",
    "    return flags\n",
    "\n",
    "features = df_by_ticker.apply(lambda trade: create_features(trade), axis=1)\n",
    "\n",
    "\n",
    "# Looks at the last valid trading date on or before the transaction date.\n",
    "def get_spy_return(effective_date, spy_history):\n",
    "    \"\"\"Returns SPY's 1-day return for the last valid trading day <= effective_date\"\"\"\n",
    "    # Get all SPY dates <= effective_date\n",
    "    valid_dates = spy_history.index[spy_history.index.date <= effective_date]\n",
    "    \n",
    "    if len(valid_dates) == 0:\n",
    "        return np.nan  # No previous trading data\n",
    "    \n",
    "    # Take the closest trading date\n",
    "    dt = valid_dates[-1]\n",
    "    return (spy_history.loc[dt, 'Close'] / spy_history.loc[dt, 'Open']) - 1\n",
    "\n",
    "df_by_ticker['SPY_1d_return'] = df_by_ticker['eff_trans_date'].apply(\n",
    "    lambda x: get_spy_return(x, spy_history)\n",
    ")\n",
    "\n",
    "\n",
    "df_by_ticker[features.columns] = features\n",
    "df_by_ticker['month_end_flag'] = flag_month_end(df_by_ticker['trade_date'])\n",
    "df_by_ticker = df_by_ticker.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bb41c",
   "metadata": {},
   "source": [
    "### Create target variable for price movement more than x%\n",
    "#### True for increase, False for decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(prices):\n",
    "    targets = {}\n",
    "\n",
    "    targets['next_day'] = 1 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week'] = 1 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month'] = 1 < prices['Close'].iloc[20]/prices['Open'].iloc[0] #weekends not included => 1 week = 5 elements\n",
    "\n",
    "    targets['next_day_2%'] = 1.02 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week_2%'] = 1.02 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month_2%'] = 1.02 < prices['Close'].iloc[20]/prices['Open'].iloc[0]\n",
    "\n",
    "\n",
    "    targets['next_day_5%'] = 1.05 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week_5%'] = 1.05 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month_5%'] = 1.05 < prices['Close'].iloc[20]/prices['Open'].iloc[0]\n",
    "\n",
    "\n",
    "    return pd.Series(targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "targets = df_by_ticker.apply(lambda trade: create_targets(trade['future_prices']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25abad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_ticker.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf13b4f",
   "metadata": {},
   "source": [
    "## prediction 1 day higher (1) lower (0) price movements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e39828",
   "metadata": {},
   "source": [
    "\n",
    "### (think about making that higher or lower than a x% increase, whatever the cut off is)\n",
    "\n",
    "1. Binomial Logistic Regression (Good Baseline): An issue with this is that not all variables will be linearly independant. Good to get as many finacial ratios and indicators leading up to the purchase. But still do real basic analysis.\n",
    "\n",
    "2. Random Forest: better for nonlin relationships, machine learning supervised classification modele.\n",
    "\n",
    "****** 3. XGBoost is best \"XGBoost with well-engineered features outperforms both binomial regression and deep learning in production.\", best with tabular data. Min samples 5k, ideal >50k sample.\n",
    "\n",
    "4. LSTM, for time series data (price data leading up to the date of purchase.) clean data, GPU resources, >50,000 samples required\n",
    "\n",
    "\n",
    "\n",
    "#### To be added\n",
    "days_since_earnings\n",
    "\n",
    "Sector_ETF_5d_trend\n",
    "\n",
    "VIX_level\n",
    "\n",
    "This could be good to put in as well only if the filing_lag_days has some significance:\n",
    "\n",
    "```\n",
    "df['urgent_filing'] = (df['filing_lag_days'] <= 1).astype(int)  # Binary flag\n",
    "df['lag_x_volume'] = df['filing_lag_days'] * df['trade_volume']  # Interaction term\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61914968",
   "metadata": {},
   "source": [
    "#### GPT bullhsit you could add but i can't be bothered rn\n",
    "\n",
    "### **1. Insider-Specific Features**\n",
    "1. **`insider_cluster_size`**  \n",
    "   - Number of unique insiders trading the same stock within 5 days  \n",
    "   ```python\n",
    "   df['insider_cluster_size'] = df.groupby(['ticker', pd.Grouper(key='trade_date', freq='5D')])['owner_names'].transform('nunique')\n",
    "   ```\n",
    "\n",
    "2. **`title_rank`**  \n",
    "   - Numeric hierarchy of insider titles (CEO=4, CFO=3, Director=2, Other=1)  \n",
    "   ```python\n",
    "   title_rank = {'CEO':4, 'CFO':3, 'Director':2}\n",
    "   df['title_rank'] = df['Title'].map(title_rank).fillna(1)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Advanced Market Context**\n",
    "3. **`sector_relative_strength`**  \n",
    "   - Stock's 5-day return vs sector ETF (e.g., XLK for tech)  \n",
    "   ```python\n",
    "   df['sector_relative_strength'] = df['1mo_return'] - sector_etf_returns\n",
    "   ```\n",
    "\n",
    "4. **`vix_1d_change`**  \n",
    "   - Daily % change in VIX (volatility spike indicator)  \n",
    "   ```python\n",
    "   df['vix_1d_change'] = vix_data['Close'].pct_change().loc[df['eff_trans_date']].values\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Technical Enhancements**\n",
    "5. **`atr_14`**  \n",
    "   - Average True Range (volatility normalization)  \n",
    "   ```python\n",
    "   df['atr_14'] = talib.ATR(df['High'], df['Low'], df['Close'], 14)\n",
    "   ```\n",
    "\n",
    "6. **`obv_5d`**  \n",
    "   - 5-day On-Balance Volume trend  \n",
    "   ```python\n",
    "   df['obv_5d'] = talib.OBV(df['Close'], df['Volume']).pct_change(5)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Behavioral Signals**\n",
    "7. **`short_interest_ratio`**  \n",
    "   - Short interest / float (squeeze potential)  \n",
    "   ```python\n",
    "   df['short_interest_ratio'] = df['ticker'].map(short_interest_data)\n",
    "   ```\n",
    "\n",
    "8. **`earnings_proximity`**  \n",
    "   - Days until next earnings (-30 to +30, 0=earnings day)  \n",
    "   ```python\n",
    "   df['earnings_proximity'] = (earnings_dates - df['trade_date']).dt.days\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Risk Management**\n",
    "9. **`beta_1mo`**  \n",
    "   - Stock's 1-month beta to SPY  \n",
    "   ```python\n",
    "   df['beta_1mo'] = df['ticker'].map(beta_calculations)\n",
    "   ```\n",
    "\n",
    "10. **`liquidity_zscore`**  \n",
    "    - Current volume vs 3-month avg (z-score)  \n",
    "    ```python\n",
    "    df['liquidity_zscore'] = (df['Volume'] - df['Volume'].rolling(63).mean()) / df['Volume'].rolling(63).std()\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632bf08",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = targets['next_day_2%']\n",
    "X = df_by_ticker.drop(['transaction_date', 'trade_date', 'eff_trans_date', 'ticker','company_name', 'owner_names', 'prev_prices', 'future_prices', 'Title'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Spliting Train Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_leaf_nodes=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=90,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac867099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred) \n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2)) \n",
    "# Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecad86",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0653b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botenv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
