{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8037d622",
   "metadata": {},
   "source": [
    "for more scope creep, using a 30 (or 60 or 90) day price plot estimate the most likley day that the stock will peak and use this as the sell date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed29407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "from pandas.tseries.offsets import BMonthEnd\n",
    "#from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "#import tensorflow as tf\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix # Loading required libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8565bf0",
   "metadata": {},
   "source": [
    "## Load data into df_by_ticker\n",
    "\n",
    "df_by_ticker has columns such as 'transaction_date', 'trade_date', 'eff_trans_date', 'ticker','company_name', 'owner_names', 'prev_prices', 'future_prices', 'Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72053cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "<>:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "C:\\Users\\azzag\\AppData\\Local\\Temp\\ipykernel_27740\\3325002570.py:9: SyntaxWarning: \"\\$\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\$\"? A raw string is also an option.\n",
      "  .str.replace('[\\$,\\+\\-\\%>]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('2015_2025_data/insider_trades.csv', parse_dates=['transaction_date', 'trade_date'])\n",
    "df = df.dropna()\n",
    "\n",
    "for i in ['last_price', 'Qty', 'shares_held', 'Owned', 'Value']:\n",
    "    df[i] = (\n",
    "        df[i]\n",
    "        .astype(str)\n",
    "        .str.replace('New', '1000000000', regex=False)\n",
    "        .str.replace('[\\$,\\+\\-\\%>]', '', regex=True)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'], format=\"%d/%m/%Y %H:%M\")\n",
    "df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "\n",
    "def adjust_transaction_date(dt):\n",
    "    if dt.hour < 9 or (dt.hour == 9 and dt.minute < 30):\n",
    "        return (dt - pd.Timedelta(days=1)).date()\n",
    "    else:\n",
    "        return dt.date()\n",
    "\n",
    "df['eff_trans_date'] = df['transaction_date'].apply(adjust_transaction_date)\n",
    "\n",
    "df['Owned_norm'] = 1 - np.exp(-df['Owned']*np.log(2)/100)\n",
    "\n",
    "df = df.sort_values(by='transaction_date')\n",
    "\n",
    "#df = df.loc[:499]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b47742a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_date', 'trade_date', 'ticker', 'company_name',\n",
       "       'owner_name', 'Title', 'transaction_type', 'last_price', 'Qty',\n",
       "       'shares_held', 'Owned', 'Value', 'eff_trans_date', 'Owned_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_by_ticker = df.copy()\n",
    "df_by_ticker.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b3611",
   "metadata": {},
   "source": [
    "### Saving and loading varilabes with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d88baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLoading a variable\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.makedirs('saved_vars', exist_ok=True)  # create folder if it doesn't exist\n",
    "\n",
    "'''\n",
    "Saving a variable\n",
    "'''\n",
    "#with open('saved_vars/prices_for_all_tickers.pkl', 'wb') as f:\n",
    "#    pickle.dump(prices, f)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Loading a variable\n",
    "'''\n",
    "#with open('saved_vars/500_trades_from_mid_2024.pkl', 'rb') as f:  # 'rb' = read binary\n",
    "#    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01492426",
   "metadata": {},
   "source": [
    "## Loading ticker prices into `prices`\n",
    "\n",
    "`prices` is a pd serise indexed by the ticker names, where each element is pd df with 5 cols, open, high, low, close, volume, with those prices from 2015 to 2025 (or later). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed685b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_vars/Formatted_ticker_data_2015_2025.pkl', 'rb') as f:  # 'rb' = read binary\n",
    "    prices = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826eb1fc",
   "metadata": {},
   "source": [
    "## Putting 90days of prices into df_by_ticker\n",
    "\n",
    "Currently `df_by_ticker` has no price data, and prices has price data from 2015-25, we will select just the 90 days leading up to the trasaction date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f06eea7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many levels: Index has only 1 level, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m     row = {\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m: trade[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mprev_prices\u001b[39m\u001b[33m'\u001b[39m: prev_price,\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfuture_prices\u001b[39m\u001b[33m'\u001b[39m : future_price\n\u001b[32m     15\u001b[39m     }\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df_ticker_data = \u001b[43mdf_by_ticker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_ticker_data_from_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexpand\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m df_by_ticker[\u001b[33m'\u001b[39m\u001b[33mprev_prices\u001b[39m\u001b[33m'\u001b[39m] = df_ticker_data[\u001b[33m'\u001b[39m\u001b[33mprev_prices\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     21\u001b[39m df_by_ticker[\u001b[33m'\u001b[39m\u001b[33mfuture_prices\u001b[39m\u001b[33m'\u001b[39m] = df_ticker_data[\u001b[33m'\u001b[39m\u001b[33mfuture_prices\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_ticker_data_from_cache\u001b[39m\u001b[34m(trade)\u001b[39m\n\u001b[32m      3\u001b[39m ticker_prices = prices[trade[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      5\u001b[39m prev_price = ticker_prices.loc[trade[\u001b[33m'\u001b[39m\u001b[33meff_trans_date\u001b[39m\u001b[33m'\u001b[39m] - timedelta(days=\u001b[32m100\u001b[39m):trade[\u001b[33m'\u001b[39m\u001b[33meff_trans_date\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m prev_price.columns = \u001b[43mprev_price\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdroplevel\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m future_price = ticker_prices.loc[trade[\u001b[33m'\u001b[39m\u001b[33meff_trans_date\u001b[39m\u001b[33m'\u001b[39m]+ timedelta(days=\u001b[32m1\u001b[39m) : trade[\u001b[33m'\u001b[39m\u001b[33meff_trans_date\u001b[39m\u001b[33m'\u001b[39m] + timedelta(days=\u001b[32m31\u001b[39m)]\n\u001b[32m      9\u001b[39m future_price.columns = future_price.columns.droplevel(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2162\u001b[39m, in \u001b[36mIndex.droplevel\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(level, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m   2160\u001b[39m     level = [level]\n\u001b[32m-> \u001b[39m\u001b[32m2162\u001b[39m levnums = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m[::-\u001b[32m1\u001b[39m]\n\u001b[32m   2164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._drop_level_numbers(levnums)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2162\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   2159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(level, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m   2160\u001b[39m     level = [level]\n\u001b[32m-> \u001b[39m\u001b[32m2162\u001b[39m levnums = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;129;01min\u001b[39;00m level)[::-\u001b[32m1\u001b[39m]\n\u001b[32m   2164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._drop_level_numbers(levnums)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2024\u001b[39m, in \u001b[36mIndex._get_level_number\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2023\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_level_number\u001b[39m(\u001b[38;5;28mself\u001b[39m, level) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2024\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2015\u001b[39m, in \u001b[36mIndex._validate_index_level\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2010\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m   2011\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mToo many levels: Index has only 1 level, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2012\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid level number\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2013\u001b[39m         )\n\u001b[32m   2014\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2015\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m   2016\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mToo many levels: Index has only 1 level, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2017\u001b[39m         )\n\u001b[32m   2018\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m level != \u001b[38;5;28mself\u001b[39m.name:\n\u001b[32m   2019\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   2020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequested level (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) does not match index name (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2021\u001b[39m     )\n",
      "\u001b[31mIndexError\u001b[39m: Too many levels: Index has only 1 level, not 2"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Slice per row from this cached dataset\n",
    "def get_ticker_data_from_cache(trade):\n",
    "    ticker_prices = prices[trade['ticker']]\n",
    "    \n",
    "    prev_price = ticker_prices.loc[trade['eff_trans_date'] - timedelta(days=100):trade['eff_trans_date']]\n",
    "    prev_price.columns = prev_price.columns.droplevel(1)\n",
    "\n",
    "    future_price = ticker_prices.loc[trade['eff_trans_date']+ timedelta(days=1) : trade['eff_trans_date'] + timedelta(days=31)]\n",
    "    future_price.columns = future_price.columns.droplevel(1)\n",
    "\n",
    "    row = {\n",
    "        'ticker': trade['ticker'],\n",
    "        'prev_prices': prev_price,\n",
    "        'future_prices' : future_price\n",
    "    }\n",
    "    return row\n",
    "\n",
    "df_ticker_data = df_by_ticker.apply(get_ticker_data_from_cache, axis=1, result_type='expand')\n",
    "\n",
    "df_by_ticker['prev_prices'] = df_ticker_data['prev_prices']\n",
    "df_by_ticker['future_prices'] = df_ticker_data['future_prices']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31713feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_date    2015-01-02 12:02:10\n",
      "trade_date          2015-01-02 00:00:00\n",
      "ticker                             TKOI\n",
      "company_name               Telkonet Inc\n",
      "owner_name              Davis William H\n",
      "Title                               Dir\n",
      "transaction_type           P - Purchase\n",
      "last_price                         0.15\n",
      "Qty                             10714.0\n",
      "shares_held                   1375854.0\n",
      "Owned                               1.0\n",
      "Value                            1554.0\n",
      "eff_trans_date               2015-01-02\n",
      "Owned_norm                     0.006908\n",
      "Name: 5574, dtype: object\n",
      "Price         Open   High     Low   Close  Volume\n",
      "Date                                             \n",
      "2014-09-24  0.1650  0.165  0.1649  0.1649   30000\n",
      "2014-09-25  0.1630  0.163  0.1630  0.1630    1000\n",
      "2014-09-26  0.1700  0.170  0.1630  0.1630   30000\n",
      "2014-09-29  0.1630  0.168  0.1610  0.1610   35800\n",
      "2014-09-30  0.1610  0.169  0.1600  0.1600   37203\n",
      "...            ...    ...     ...     ...     ...\n",
      "2014-12-26  0.1410  0.149  0.1400  0.1450   69906\n",
      "2014-12-29  0.1450  0.145  0.1300  0.1400  544294\n",
      "2014-12-30  0.1399  0.149  0.1320  0.1490   85278\n",
      "2014-12-31  0.1350  0.143  0.1330  0.1400  433721\n",
      "2015-01-02  0.1400  0.145  0.1390  0.1450   88926\n",
      "\n",
      "[70 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "trade = df_by_ticker.iloc[10]\n",
    "print(trade)\n",
    "\n",
    "ticker_prices = prices[trade['ticker']]\n",
    "\n",
    "prev_price = ticker_prices.loc[trade['eff_trans_date'] - timedelta(days=100):trade['eff_trans_date']]\n",
    "print(prev_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e85629",
   "metadata": {},
   "source": [
    "## Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354a1a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prev_prices'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'prev_prices'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m         flags.append(\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m last_3_days \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m flags\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m features = \u001b[43mdf_by_ticker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Looks at the last valid trading date on or before the transaction date.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_spy_return\u001b[39m(effective_date, spy_history):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trade)\u001b[39m\n\u001b[32m     70\u001b[39m         flags.append(\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m last_3_days \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m flags\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m features = df_by_ticker.apply(\u001b[38;5;28;01mlambda\u001b[39;00m trade: \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Looks at the last valid trading date on or before the transaction date.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_spy_return\u001b[39m(effective_date, spy_history):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcreate_features\u001b[39m\u001b[34m(trade)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_features\u001b[39m(trade):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    ticker_data: DataFrame with OHLCV for one stock over 3 months\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Returns: Single row of engineered features:\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m        '1mo_return', '3mo_return', '30d_volatility', 'rsi_14', 'macd',\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m        'volume_zscore', 'price_vs_sma50'.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     ticker_data = \u001b[43mtrade\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprev_prices\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m     features = {}\n\u001b[32m     12\u001b[39m     features[\u001b[33m'\u001b[39m\u001b[33mtrade_date_epoch\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(trade[\u001b[33m'\u001b[39m\u001b[33mtrade_date\u001b[39m\u001b[33m'\u001b[39m]).timestamp() \u001b[38;5;66;03m# seconds since epoch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\azzag\\Documents\\Programming\\Python\\TradingBot\\botenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'prev_prices'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_features(trade):\n",
    "    \"\"\"\n",
    "    ticker_data: DataFrame with OHLCV for one stock over 3 months\n",
    "    Returns: Single row of engineered features:\n",
    "        '1mo_return', '3mo_return', '30d_volatility', 'rsi_14', 'macd',\n",
    "        'volume_zscore', 'price_vs_sma50'.\n",
    "    \"\"\"\n",
    "    ticker_data = trade['prev_prices']\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    features['trade_date_epoch'] = pd.to_datetime(trade['trade_date']).timestamp() # seconds since epoch\n",
    "    features['eff_trans_date_epoch'] = pd.to_datetime(trade['eff_trans_date']).timestamp() \n",
    "\n",
    "    \n",
    "    # Price returns\n",
    "    features['1mo_return'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].iloc[-22] - 1\n",
    "    features['3mo_return'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].iloc[-63] - 1\n",
    "    \n",
    "    # Volatility\n",
    "    features['30d_volatility'] = ticker_data['Close'].pct_change().std() * np.sqrt(252)\n",
    "    \n",
    "    # Momentum indicators\n",
    "    # RSI 14\n",
    "    rsi = RSIIndicator(close=ticker_data['Close'], window=14).rsi()  # series\n",
    "    features['rsi_14'] = rsi.iloc[-1]\n",
    "    # MACD line\n",
    "    macd = MACD(close=ticker_data['Close'])\n",
    "    features['macd'] = macd.macd().iloc[-1]  # MACD line\n",
    "    \n",
    "    # Volume\n",
    "    features['volume_zscore'] = (\n",
    "        (ticker_data['Volume'].iloc[-1] - ticker_data['Volume'].mean()) \n",
    "        / ticker_data['Volume'].std()\n",
    "    )\n",
    "    \n",
    "    # Trend relationships\n",
    "    features['price_vs_sma50'] = ticker_data['Close'].iloc[-1] / ticker_data['Close'].rolling(50).mean().iloc[-1]\n",
    "\n",
    "    # Bool on whether the transaction was made within trading hours.\n",
    "    features['is_during_market_hours'] = time(hour=9, minute=30) < trade['transaction_date'].time() < time(hour=16)\n",
    "\n",
    "    # Day of the week the trade was made on.\n",
    "    features['day_of_week'] = trade['trade_date'].dayofweek\n",
    "\n",
    "    # Number of days between making the trade and filing with the SEC\n",
    "    features['filing_lad_days'] = (trade['transaction_date']-trade['trade_date']).days\n",
    "\n",
    "    #df_by_ticker = df_by_ticker.dropna()\n",
    "    \n",
    "    title_str = ''.join(trade['Title'])\n",
    "    if 'CEO' in title_str:\n",
    "        features['title_rank'] = 4\n",
    "    elif 'C' in title_str:\n",
    "        features['title_rank'] = 3\n",
    "    elif 'Dir' in title_str:\n",
    "        features['title_rank'] = 2\n",
    "    else:\n",
    "        features['title_rank'] = 1\n",
    "        \n",
    "    return pd.Series(features)\n",
    "\n",
    "\n",
    "def flag_month_end(trade_dates):\n",
    "    \"\"\"Returns 1 for last 3 business days of month\"\"\"\n",
    "    flags = []\n",
    "    for date in trade_dates:\n",
    "        month_end = BMonthEnd().rollforward(date)  # Get official month-end\n",
    "        last_3_days = pd.bdate_range(end=month_end, periods=3)  # Last 3 trading days\n",
    "        flags.append(1 if date in last_3_days else 0)\n",
    "    return flags\n",
    "\n",
    "features = df_by_ticker.apply(lambda trade: create_features(trade), axis=1)\n",
    "\n",
    "\n",
    "# Looks at the last valid trading date on or before the transaction date.\n",
    "def get_spy_return(effective_date, spy_history):\n",
    "    \"\"\"Returns SPY's 1-day return for the last valid trading day <= effective_date\"\"\"\n",
    "    # Get all SPY dates <= effective_date\n",
    "    valid_dates = spy_history.index[spy_history.index.date <= effective_date]\n",
    "    \n",
    "    if len(valid_dates) == 0:\n",
    "        return np.nan  # No previous trading data\n",
    "    \n",
    "    # Take the closest trading date\n",
    "    dt = valid_dates[-1]\n",
    "    return (spy_history.loc[dt, 'Close'] / spy_history.loc[dt, 'Open']) - 1\n",
    "\n",
    "df_by_ticker['SPY_1d_return'] = df_by_ticker['eff_trans_date'].apply(\n",
    "    lambda x: get_spy_return(x, spy_history)\n",
    ")\n",
    "\n",
    "\n",
    "df_by_ticker[features.columns] = features\n",
    "df_by_ticker['month_end_flag'] = flag_month_end(df_by_ticker['trade_date'])\n",
    "df_by_ticker = df_by_ticker.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bb41c",
   "metadata": {},
   "source": [
    "### Create target variable for price movement more than x%\n",
    "#### True for increase, False for decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(prices):\n",
    "    targets = {}\n",
    "\n",
    "    targets['next_day'] = 1 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week'] = 1 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month'] = 1 < prices['Close'].iloc[20]/prices['Open'].iloc[0] #weekends not included => 1 week = 5 elements\n",
    "\n",
    "    targets['next_day_2%'] = 1.02 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week_2%'] = 1.02 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month_2%'] = 1.02 < prices['Close'].iloc[20]/prices['Open'].iloc[0]\n",
    "\n",
    "\n",
    "    targets['next_day_5%'] = 1.05 < prices['Close'].iloc[0]/prices['Open'].iloc[0]\n",
    "    targets['one_week_5%'] = 1.05 < prices['Close'].iloc[5]/prices['Open'].iloc[0]\n",
    "    targets['one_month_5%'] = 1.05 < prices['Close'].iloc[20]/prices['Open'].iloc[0]\n",
    "\n",
    "\n",
    "    return pd.Series(targets)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "targets = df_by_ticker.apply(lambda trade: create_targets(trade['future_prices']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25abad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_ticker.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf13b4f",
   "metadata": {},
   "source": [
    "## prediction 1 day higher (1) lower (0) price movements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e39828",
   "metadata": {},
   "source": [
    "\n",
    "### (think about making that higher or lower than a x% increase, whatever the cut off is)\n",
    "\n",
    "1. Binomial Logistic Regression (Good Baseline): An issue with this is that not all variables will be linearly independant. Good to get as many finacial ratios and indicators leading up to the purchase. But still do real basic analysis.\n",
    "\n",
    "2. Random Forest: better for nonlin relationships, machine learning supervised classification modele.\n",
    "\n",
    "****** 3. XGBoost is best \"XGBoost with well-engineered features outperforms both binomial regression and deep learning in production.\", best with tabular data. Min samples 5k, ideal >50k sample.\n",
    "\n",
    "4. LSTM, for time series data (price data leading up to the date of purchase.) clean data, GPU resources, >50,000 samples required\n",
    "\n",
    "\n",
    "\n",
    "#### To be added\n",
    "days_since_earnings\n",
    "\n",
    "Sector_ETF_5d_trend\n",
    "\n",
    "VIX_level\n",
    "\n",
    "This could be good to put in as well only if the filing_lag_days has some significance:\n",
    "\n",
    "```\n",
    "df['urgent_filing'] = (df['filing_lag_days'] <= 1).astype(int)  # Binary flag\n",
    "df['lag_x_volume'] = df['filing_lag_days'] * df['trade_volume']  # Interaction term\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61914968",
   "metadata": {},
   "source": [
    "#### GPT bullhsit you could add but i can't be bothered rn\n",
    "\n",
    "### **1. Insider-Specific Features**\n",
    "1. **`insider_cluster_size`**  \n",
    "   - Number of unique insiders trading the same stock within 5 days  \n",
    "   ```python\n",
    "   df['insider_cluster_size'] = df.groupby(['ticker', pd.Grouper(key='trade_date', freq='5D')])['owner_names'].transform('nunique')\n",
    "   ```\n",
    "\n",
    "2. **`title_rank`**  \n",
    "   - Numeric hierarchy of insider titles (CEO=4, CFO=3, Director=2, Other=1)  \n",
    "   ```python\n",
    "   title_rank = {'CEO':4, 'CFO':3, 'Director':2}\n",
    "   df['title_rank'] = df['Title'].map(title_rank).fillna(1)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Advanced Market Context**\n",
    "3. **`sector_relative_strength`**  \n",
    "   - Stock's 5-day return vs sector ETF (e.g., XLK for tech)  \n",
    "   ```python\n",
    "   df['sector_relative_strength'] = df['1mo_return'] - sector_etf_returns\n",
    "   ```\n",
    "\n",
    "4. **`vix_1d_change`**  \n",
    "   - Daily % change in VIX (volatility spike indicator)  \n",
    "   ```python\n",
    "   df['vix_1d_change'] = vix_data['Close'].pct_change().loc[df['eff_trans_date']].values\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Technical Enhancements**\n",
    "5. **`atr_14`**  \n",
    "   - Average True Range (volatility normalization)  \n",
    "   ```python\n",
    "   df['atr_14'] = talib.ATR(df['High'], df['Low'], df['Close'], 14)\n",
    "   ```\n",
    "\n",
    "6. **`obv_5d`**  \n",
    "   - 5-day On-Balance Volume trend  \n",
    "   ```python\n",
    "   df['obv_5d'] = talib.OBV(df['Close'], df['Volume']).pct_change(5)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Behavioral Signals**\n",
    "7. **`short_interest_ratio`**  \n",
    "   - Short interest / float (squeeze potential)  \n",
    "   ```python\n",
    "   df['short_interest_ratio'] = df['ticker'].map(short_interest_data)\n",
    "   ```\n",
    "\n",
    "8. **`earnings_proximity`**  \n",
    "   - Days until next earnings (-30 to +30, 0=earnings day)  \n",
    "   ```python\n",
    "   df['earnings_proximity'] = (earnings_dates - df['trade_date']).dt.days\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Risk Management**\n",
    "9. **`beta_1mo`**  \n",
    "   - Stock's 1-month beta to SPY  \n",
    "   ```python\n",
    "   df['beta_1mo'] = df['ticker'].map(beta_calculations)\n",
    "   ```\n",
    "\n",
    "10. **`liquidity_zscore`**  \n",
    "    - Current volume vs 3-month avg (z-score)  \n",
    "    ```python\n",
    "    df['liquidity_zscore'] = (df['Volume'] - df['Volume'].rolling(63).mean()) / df['Volume'].rolling(63).std()\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632bf08",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = targets['next_day_2%']\n",
    "X = df_by_ticker.drop(['transaction_date', 'trade_date', 'eff_trans_date', 'ticker','company_name', 'owner_names', 'prev_prices', 'future_prices', 'Title'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Spliting Train Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_leaf_nodes=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=90,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac867099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred) \n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2)) \n",
    "# Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecad86",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0653b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botenv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
